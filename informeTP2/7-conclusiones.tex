\section{Conclusiones y trabajo futuro}

    A partir de los experimentos realizados en este trabajo, se pudo llegar a la conclusión de que las ventajas que puede brindar el paradigma \textbf{SIMD} a la hora de implementar programas que realicen operaciones altamente paralelizables, como el procesamiento de imágenes, son verdaderamente significativas. Esto queda reflejado en la gran brecha de rendimiento que se observa entre algunas implementaciones realizadas con dicho paradigma y las que utilizan el lenguaje de programación C.

    Esto siempre debe contraponerse a otro hecho que se hizo presente durante el proceso de implementación: realizar un programa en lenguaje ensamblador resulta, por lo general, considerablemente más difícil que hacerlo en un lenguaje de más alto nivel. El código resultante es menos legible, es más sencillo cometer errores y el proceso de \emph{debugging} se vuelve considerablemente más arduo. Por eso es importante analizar de antemano las características del contexto particular de aplicación, para poder decidir si este esfuerzo adicional realmente vale la pena.

    Efectivamente a la hora de contraponer el filtro de Monocromatizar implementado en ASM con SISD e implementado con SIMD, pudimos notar que el desempeño del algoritmo implementado en SISD no ofrece mejoras significativas con entradas de menor tamaño, menos aún en comparación a la performance que obtuvo la versión de procesamiendo paralelo con SIMD y a las dificultades relativas de escribir código en ASM contra C. Habrá que tener en cuenta a la hora de la implementación detalles como el usuario final del producto, los datos con los cuales se va a trabajar y cuánto mantenimiento requerirá la aplicación que los utilice.

    Ahondando en los detalles más técnicos de la implementación, se intentó la realización de una optimización manual dentro del código ensamblador, sin obtener resultados destacables. La razón de esto es que la estructura del código dificultaba ampliamente la realización de dicha modificación. Realizar la optimización de manera efectiva habría implicado modificar gran parte del código ya armado, con un costo casi equivalente al de empezarlo de nuevo con un enfoque distinto; esto es consecuencia de la ya mencionada dificultad que presenta mantener el código programado en este lenguaje.

    También pudimos observar las mejoras que introduce el predictor de saltos y el pipeline en la ejecución de los programas forzando casos particulares de datos de entrada. Ahora podemos tener en cuenta algunos de estos resultados para escribir código que sea más eficiente, logrando explotar la arquitectura y el diseño del computador: sabemos que el orden de los branches puede afectar notoriamente los tiempos de ejecución, de la misma manera que podemos aprovechar el conocimiento del tamaño de la memoria caché para evitar escribir código que produzca muchos misses durante la ejecución, asimismo tener información sobre los datos de entrada va a resultar crucial para poder optimizar estas herramientas.

    En conclusión, una vez terminado este trabajo y concluídos los experimentos tenemos certeza de haber descubierto la importancia de las técnicas utilizadas y los conceptos explorados para nuestra formación y para nuestro futuro profesional. Si bien una etapa de la experimentación estuvo basada en escenarios de trabajo a bajo nivel -y por ende, aplicables directamente a un campo más específico-, todos los resultados obtenidos impartieron conocimiento sobre la arquitectura Intel y sobre cómo reflexionar para hacerla funcionar a nuestro beneficio. Esperamos poder investigar más en profundidad estos aspectos y conocer otros de igual importancia en el contexto de la materia.